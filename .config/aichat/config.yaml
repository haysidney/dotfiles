# see https://github.com/sigoden/aichat/blob/main/config.example.yaml

model: ollama:qwen3:14b
clients:
- type: openai-compatible
  name: ollama
  api_base: http://localhost:11434/v1
  models:
  - name: qwen3-embedding:8b
    type: embedding
    default_chunk_size: 1000
    max_batch_size: 100
  - name: qwen3:8b
  - name: qwen3:14b
  - name: qwen3:30b
